{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recomendador de Musica con Base de Datos de Spotify**\n",
    "\n",
    "En esta notebook se realizará un motor de Recomendación de Canciones a partir de una base de datos pequeña de spotify.\n",
    "Empezaré con un EDA para saber como utilizar el dataset. Luego ya que tenga entienda la base la ajustare al problema para que pueda ser mas facil de utilizarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:20.715330Z",
     "iopub.status.busy": "2021-12-17T05:44:20.714397Z",
     "iopub.status.idle": "2021-12-17T05:44:21.808185Z",
     "shell.execute_reply": "2021-12-17T05:44:21.807394Z",
     "shell.execute_reply.started": "2021-12-17T05:44:20.715276Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Leemos los Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:21.810083Z",
     "iopub.status.busy": "2021-12-17T05:44:21.809689Z",
     "iopub.status.idle": "2021-12-17T05:44:22.522129Z",
     "shell.execute_reply": "2021-12-17T05:44:22.521334Z",
     "shell.execute_reply.started": "2021-12-17T05:44:21.810053Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data_tracks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:22.523745Z",
     "iopub.status.busy": "2021-12-17T05:44:22.523285Z",
     "iopub.status.idle": "2021-12-17T05:44:22.617801Z",
     "shell.execute_reply": "2021-12-17T05:44:22.616916Z",
     "shell.execute_reply.started": "2021-12-17T05:44:22.523696Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar todos los parametros con la columna **'popularidad'**. Antes de ir a hacer eso vamos a comprobar la Correlación de Características considerando algunas características y para eso, voy a utilizar el paquete **yellowbrick**. Puedes aprender más sobre él en la página [documentation](https://www.scikit-yb.org/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:22.650055Z",
     "iopub.status.busy": "2021-12-17T05:44:22.649461Z",
     "iopub.status.idle": "2021-12-17T05:44:22.923236Z",
     "shell.execute_reply": "2021-12-17T05:44:22.922246Z",
     "shell.execute_reply.started": "2021-12-17T05:44:22.650012Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n",
    "\n",
    "X, y = data[feature_names], data['popularity']\n",
    "\n",
    "# Creamos una lista con los nombres de las caracteristicas\n",
    "features = np.array(feature_names)\n",
    "\n",
    "# Creamos la instancia\n",
    "visualizer = FeatureCorrelation(labels=features)\n",
    "\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "visualizer.fit(X, y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estadística, el coeficiente de correlación de Pearson es una medida de dependencia lineal entre dos variables aleatorias cuantitativas. A diferencia de la covarianza, la correlación de Pearson es independiente de la escala de medida de las variables.\n",
    "\n",
    "De manera menos formal, podemos definir el coeficiente de correlación de Pearson como un índice que puede utilizarse para medir el grado de relación de dos variables siempre y cuando ambas sean cuantitativas y continuas. \n",
    "\n",
    "\n",
    "Correlación positiva: significa que si la característica A aumenta, la característica B también aumenta o si la característica A disminuye, la característica B también disminuye. Ambas características se mueven en tándem y tienen una relación lineal.\n",
    "\n",
    "\n",
    "Correlación negativa: significa que si la característica A aumenta, la característica B disminuye y viceversa.\n",
    "\n",
    "Sin correlación: No hay relación entre esos dos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de canciones por década"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade(year):\n",
    "    period_start = int(year/10) * 10\n",
    "    decade = '{}s'.format(period_start)\n",
    "    return decade\n",
    "\n",
    "data['decade'] = data['year'].apply(get_decade)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12 ,8)})\n",
    "sns.countplot(data['decade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Agrupación de canciones con K-Means**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler() normalizará las características (cada columna de X, INDIVIDUALMENTE !!!) para que cada columna/característica/variable tenga mean = 0 y standard deviation = 1. \n",
    "\n",
    "\n",
    "K-means es un algoritmo de clasificación no supervisada (clusterización) que agrupa objetos en k grupos basándose en sus características. El agrupamiento se realiza minimizando la suma de distancias entre cada objeto y el centroide de su grupo o cluster. Se suele usar la distancia cuadrática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "track_uri = \"http://localhost:5000/\" # Esto puede ser que cambie por http://0.0.0.0:1234\n",
    "mlflow.set_tracking_uri(track_uri)\n",
    "mlflow.set_registry_uri(\"sqlite:////tmp/registry.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generando el experimento o cargandolo si existe\n",
    "experiment_name = \"Bot_Recomendador\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Cargando la información\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Vamos a ver si es cierto\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"Tracking URI: {mlflow.tracking.get_tracking_uri()}\")\n",
    "print(f\"Nombre del experimento: {experiment_name}\")\n",
    "print(f\"ID del experimento: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number_cols =['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "#            'liveness', 'speechiness', 'tempo', 'valence','duration_ms','key','year']\n",
    "number_cols = ['valence', 'danceability', 'energy', 'key', 'loudness','popularity', 'speechiness', 'tempo','year']\n",
    "\n",
    "\n",
    "#number_cols = ['danceability','popularity','year']\n",
    "n_c = 4\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "params = {\"n_clusters\": n_c}\n",
    "\n",
    "#Generamos un flujo de trabajo con dos procesos\n",
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                                  ('kmeans', KMeans(**(params), \n",
    "                                   verbose=False))\n",
    "                                 ], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasamos las columnas que utilizaremos para el entrenamiento\n",
    "X = data[number_cols]\n",
    "song_cluster_pipeline.fit(X)\n",
    "#Predecimos el grupo que pertenece cada canción\n",
    "song_cluster_labels = song_cluster_pipeline.predict(X)\n",
    "#Asignamos los labels del resultado de nuestro entrenamiento a nuestro dataframe\n",
    "data['cluster_label'] = song_cluster_labels\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.start_run()\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualizing the Clusters with PCA\n",
    "\n",
    "#Generamos un flujo de trabajo con dos procesos\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "#Vectorizamos las caracteristicas para encontrar los componentes principales\n",
    "song_embedding = pca_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
    "projection['id'] = data['id']\n",
    "projection['title'] = data['name']\n",
    "projection['cluster'] = data['cluster_label']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")\n",
    "\n",
    "fig.write_image(\"images/PCA.jpeg\")\n",
    "\n",
    "plt.savefig\n",
    "mlflow.log_artifact(\"images/PCA.jpeg\")\n",
    "\n",
    "projection.to_csv('PCA_projection.csv')\n",
    "mlflow.log_artifact('PCA_projection.csv')\n",
    "\n",
    "#mlflow.end_run()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(number_cols)\n",
    "for i in range(length):\n",
    "    projection[number_cols[i]] = projection.id.map(data.set_index('id')[number_cols[i]])\n",
    "    \n",
    "df = projection.sort_values('cluster')\n",
    "for i in range(n_c):\n",
    "    globals()['cluster%s' % i]=df.loc[df.loc[:, 'cluster'] == int(i)]\n",
    "cluster0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Construcción del Motor de recomendación**\n",
    "\n",
    "* Según el análisis y las visualizaciones, está claro que los géneros similares tienden a tener puntos de datos que se ubican cerca unos de otros, mientras que los tipos de canciones similares también se agrupan.\n",
    "* Esta observación tiene mucho sentido. Los géneros similares sonarán de manera similar y provendrán de períodos de tiempo similares, mientras que lo mismo puede decirse de las canciones dentro de esos géneros. Podemos usar esta idea para construir un sistema de recomendación tomando los puntos de datos de las canciones que un usuario ha escuchado y recomendando canciones correspondientes a puntos de datos cercanos.\n",
    "* [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/) es un cliente de Python para la API web de Spotify que facilita a los desarrolladores la obtención de datos y la consulta de canciones en el catálogo de Spotify. Tienes que instalar usando `pip install spotipy`\n",
    "* Después de instalar Spotipy, deberá crear una aplicación en la [página del desarrollador de Spotify] (https://developer.spotify.com/) y guardar su ID de cliente y clave secreta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"62cfe79d83ef43c69a7ba63f9f5debda\",\n",
    "                                                           client_secret=\"88e6707695634f04a75301fcc77d7789\"))\n",
    "\n",
    "def find_song(name):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {}'.format(name), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    # song_data['duration'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "    # song_data['loudness'] = [results['loudness']]\n",
    "    # song_data['danceability'] = [results['danceability']]\n",
    "    # song_data['energy'] = [results['energy']]\n",
    "    # song_data['tempo'] = [results['tempo']]\n",
    "    list_of_dict_values = list(results.values())\n",
    "    results_string = json.dumps(list_of_dict_values)\n",
    "    index_release_date = results_string.find(\"release_date\")\n",
    "    year_index1 = index_release_date + 16\n",
    "    year_index2 = index_release_date + 17\n",
    "    year_index3 = index_release_date + 18\n",
    "    year_index4 = index_release_date + 19\n",
    "    year_string = results_string[year_index1] + results_string[year_index2] + results_string[year_index3] + results_string[year_index4]\n",
    "    print(year_string)\n",
    "    \n",
    "    song_data['year'] = [int(year_string)]\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_data(song, spotify_data):\n",
    "    \n",
    "  #  try:\n",
    "  #      song_data = spotify_data[(spotify_data['name'] == song['name'])].iloc[0]\n",
    "  #      print(song['name'], ': si esta')\n",
    "  #      print(song['year'])\n",
    "  #      return song_data\n",
    "    \n",
    "  # except IndexError:\n",
    "  #      print(song['name'], ': no esta')\n",
    "    return find_song(song['name'])\n",
    "        \n",
    "\n",
    "def get_mean_vector(song_list, spotify_data):\n",
    "    \n",
    "    song_vectors = []\n",
    "    \n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n",
    "            continue\n",
    "        song_vector = song_data[number_cols].values\n",
    "        song_vectors.append(song_vector)  \n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)\n",
    "\n",
    "\n",
    "def flatten_dict_list(dict_list):\n",
    "    \n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n",
    "\n",
    "\n",
    "def recommend_songs( song_list, spotify_data, n_songs=3):\n",
    "    metadata_cols = ['id','name','year','artists']\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "    scaler = song_cluster_pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(spotify_data[number_cols])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n",
    "    return rec_songs[metadata_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_songs([{'name': 'Lobo Domesticado'}],  data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esta última celda te dará una lista de recomendación de canciones\n",
    "\n",
    "* Puedes cambiar la lista de canciones según tu elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec=recommend_songs([{'name': 'Lobo Domesticado'}],  data)\n",
    "rec.to_csv('Recomendacion.csv')\n",
    "mlflow.log_artifact('Recomendacion.csv')\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59c7235de5f0357eb7effc688d10d1805d2509a2e85701e981bcd2f3e5f70b26"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
